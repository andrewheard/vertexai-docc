{"topicSections":[{"identifiers":["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/init(temperature:topP:topK:candidateCount:maxOutputTokens:stopSequences:responseMIMEType:responseSchema:)"],"title":"Initializers"},{"identifiers":["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/candidateCount","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/maxOutputTokens","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/responseMIMEType","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/responseSchema","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/stopSequences","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/temperature","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/topK","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/topP"],"title":"Instance Properties"}],"sections":[],"abstract":[{"type":"text","text":"A struct defining model parameters to be used when sending generative AI"},{"type":"text","text":" "},{"text":"requests to the backend model.","type":"text"}],"hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI"]]},"metadata":{"modules":[{"name":"FirebaseVertexAI"}],"symbolKind":"struct","role":"symbol","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"kind":"identifier","text":"GenerationConfig"}],"roleHeading":"Structure","externalID":"s:16FirebaseVertexAI16GenerationConfigV","title":"GenerationConfig","platforms":[{"name":"iOS","deprecated":false,"beta":false,"introducedAt":"15.0","unavailable":false},{"unavailable":false,"deprecated":false,"name":"macOS","introducedAt":"11.0","beta":false},{"name":"Mac Catalyst","beta":false,"deprecated":false,"introducedAt":"15.0","unavailable":false},{"name":"tvOS","deprecated":false,"unavailable":false,"introducedAt":"15.0","beta":false},{"beta":false,"introducedAt":"8.0","unavailable":false,"name":"watchOS","deprecated":false}],"navigatorTitle":[{"text":"GenerationConfig","kind":"identifier"}]},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/firebasevertexai\/generationconfig"]}],"schemaVersion":{"major":0,"patch":0,"minor":3},"primaryContentSections":[{"kind":"declarations","declarations":[{"tokens":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"text":"GenerationConfig","kind":"identifier"}],"platforms":["macOS"],"languages":["swift"]}]}],"relationshipsSections":[{"identifiers":["doc:\/\/FirebaseVertexAI\/SE"],"type":"conformsTo","title":"Conforms To","kind":"relationships"}],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig"},"kind":"symbol","references":{"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/GenerationConfig/init(temperature:topP:topK:candidateCount:maxOutputTokens:stopSequences:responseMIMEType:responseSchema:)":{"abstract":[{"text":"Creates a new ","type":"text"},{"type":"codeVoice","code":"GenerationConfig"},{"text":" value.","type":"text"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/init(temperature:topP:topK:candidateCount:maxOutputTokens:stopSequences:responseMIMEType:responseSchema:)","fragments":[{"text":"init","kind":"identifier"},{"kind":"text","text":"("},{"kind":"externalParam","text":"temperature"},{"kind":"text","text":": "},{"text":"Float","kind":"typeIdentifier","preciseIdentifier":"s:Sf"},{"text":"?, ","kind":"text"},{"kind":"externalParam","text":"topP"},{"text":": ","kind":"text"},{"preciseIdentifier":"s:Sf","text":"Float","kind":"typeIdentifier"},{"kind":"text","text":"?, "},{"kind":"externalParam","text":"topK"},{"text":": ","kind":"text"},{"text":"Int","preciseIdentifier":"s:Si","kind":"typeIdentifier"},{"kind":"text","text":"?, "},{"text":"candidateCount","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"Int","kind":"typeIdentifier","preciseIdentifier":"s:Si"},{"kind":"text","text":"?, "},{"kind":"externalParam","text":"maxOutputTokens"},{"kind":"text","text":": "},{"preciseIdentifier":"s:Si","kind":"typeIdentifier","text":"Int"},{"text":"?, ","kind":"text"},{"text":"stopSequences","kind":"externalParam"},{"text":": [","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"s:SS","text":"String"},{"text":"]?, ","kind":"text"},{"kind":"externalParam","text":"responseMIMEType"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"s:SS","text":"String"},{"kind":"text","text":"?, "},{"kind":"externalParam","text":"responseSchema"},{"text":": ","kind":"text"},{"text":"Schema","kind":"typeIdentifier","preciseIdentifier":"s:16FirebaseVertexAI6SchemaC"},{"text":"?)","kind":"text"}],"type":"topic","title":"init(temperature:topP:topK:candidateCount:maxOutputTokens:stopSequences:responseMIMEType:responseSchema:)","url":"\/documentation\/firebasevertexai\/generationconfig\/init(temperature:topp:topk:candidatecount:maxoutputtokens:stopsequences:responsemimetype:responseschema:)","role":"symbol","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","kind":"symbol","abstract":[],"title":"FirebaseVertexAI","role":"collection","type":"topic","url":"\/documentation\/firebasevertexai"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/GenerationConfig/maxOutputTokens":{"abstract":[{"type":"text","text":"Specifies the maximum number of tokens that can be generated in the"},{"text":" ","type":"text"},{"type":"text","text":"response. The number of tokens per word varies depending on the"},{"type":"text","text":" "},{"type":"text","text":"language outputted. The maximum value is capped at 1024. Defaults to 0"},{"text":" ","type":"text"},{"type":"text","text":"(unbounded)."}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/maxOutputTokens","fragments":[{"kind":"keyword","text":"let"},{"text":" ","kind":"text"},{"kind":"identifier","text":"maxOutputTokens"},{"text":": ","kind":"text"},{"text":"Int","kind":"typeIdentifier","preciseIdentifier":"s:Si"},{"text":"?","kind":"text"}],"title":"maxOutputTokens","url":"\/documentation\/firebasevertexai\/generationconfig\/maxoutputtokens","type":"topic","role":"symbol","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/GenerationConfig/topP":{"fragments":[{"text":"let","kind":"keyword"},{"kind":"text","text":" "},{"text":"topP","kind":"identifier"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","text":"Float","preciseIdentifier":"s:Sf"},{"kind":"text","text":"?"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/topP","url":"\/documentation\/firebasevertexai\/generationconfig\/topp","role":"symbol","type":"topic","abstract":[{"type":"text","text":"The "},{"type":"codeVoice","code":"topP"},{"text":" parameter changes how the model selects tokens for output.","type":"text"},{"type":"text","text":" "},{"text":"Tokens are selected from the most to least probable until the sum of","type":"text"},{"type":"text","text":" "},{"type":"text","text":"their probabilities equals the "},{"code":"topP","type":"codeVoice"},{"type":"text","text":" value. For example, if tokens A, B,"},{"type":"text","text":" "},{"type":"text","text":"and C have probabilities of 0.3, 0.2, and 0.1 respectively and the topP"},{"text":" ","type":"text"},{"type":"text","text":"value is 0.5, then the model will select either A or B as the next token"},{"type":"text","text":" "},{"type":"text","text":"by using the "},{"type":"codeVoice","code":"temperature"},{"type":"text","text":" and exclude C as a candidate."},{"type":"text","text":" "},{"type":"text","text":"Defaults to 0.95 if unset."}],"kind":"symbol","title":"topP"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/GenerationConfig/stopSequences":{"abstract":[{"type":"text","text":"A set of up to 5 "},{"type":"codeVoice","code":"String"},{"type":"text","text":"s that will stop output generation. If"},{"type":"text","text":" "},{"type":"text","text":"specified, the API will stop at the first appearance of a stop sequence."},{"type":"text","text":" "},{"type":"text","text":"The stop sequence will not be included as part of the response."}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/stopSequences","fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"kind":"identifier","text":"stopSequences"},{"kind":"text","text":": ["},{"kind":"typeIdentifier","preciseIdentifier":"s:SS","text":"String"},{"text":"]?","kind":"text"}],"title":"stopSequences","url":"\/documentation\/firebasevertexai\/generationconfig\/stopsequences","type":"topic","role":"symbol","kind":"symbol"},"doc://FirebaseVertexAI/SE":{"type":"unresolvable","identifier":"doc:\/\/FirebaseVertexAI\/SE","title":"Swift.Encodable"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/GenerationConfig/responseSchema":{"abstract":[{"type":"text","text":"Output schema of the generated candidate text."},{"text":" ","type":"text"},{"type":"text","text":"If set, a compatible "},{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/responseMIMEType","isActive":true,"type":"reference"},{"type":"text","text":" must also be set."}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/responseSchema","fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"text":"responseSchema","kind":"identifier"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"s:16FirebaseVertexAI6SchemaC","text":"Schema"},{"text":"?","kind":"text"}],"title":"responseSchema","url":"\/documentation\/firebasevertexai\/generationconfig\/responseschema","type":"topic","role":"symbol","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/GenerationConfig/topK":{"kind":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/topK","type":"topic","role":"symbol","fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"text":"topK","kind":"identifier"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","text":"Int","preciseIdentifier":"s:Si"},{"kind":"text","text":"?"}],"url":"\/documentation\/firebasevertexai\/generationconfig\/topk","title":"topK","abstract":[{"text":"The ","type":"text"},{"code":"topK","type":"codeVoice"},{"type":"text","text":" parameter changes how the model selects tokens for output. A"},{"type":"text","text":" "},{"type":"codeVoice","code":"topK"},{"type":"text","text":" of 1 means the selected token is the most probable among all the"},{"type":"text","text":" "},{"type":"text","text":"tokens in the modelâ€™s vocabulary, while a "},{"code":"topK","type":"codeVoice"},{"text":" of 3 means that the next","type":"text"},{"type":"text","text":" "},{"type":"text","text":"token is selected from among the 3 most probable using the "},{"code":"temperature","type":"codeVoice"},{"type":"text","text":"."},{"type":"text","text":" "},{"text":"For each token selection step, the ","type":"text"},{"type":"codeVoice","code":"topK"},{"type":"text","text":" tokens with the highest"},{"text":" ","type":"text"},{"type":"text","text":"probabilities are sampled. Tokens are then further filtered based on"},{"type":"text","text":" "},{"type":"codeVoice","code":"topP"},{"text":" with the final token selected using ","type":"text"},{"type":"codeVoice","code":"temperature"},{"text":" sampling.","type":"text"},{"text":" ","type":"text"},{"type":"text","text":"Defaults to 40 if unspecified."}]},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/GenerationConfig/candidateCount":{"abstract":[{"type":"text","text":"The maximum number of generated response messages to return. This value"},{"text":" ","type":"text"},{"text":"must be between [1, 8], inclusive. If unset, this will default to 1.","type":"text"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/candidateCount","fragments":[{"kind":"keyword","text":"let"},{"text":" ","kind":"text"},{"text":"candidateCount","kind":"identifier"},{"text":": ","kind":"text"},{"preciseIdentifier":"s:Si","kind":"typeIdentifier","text":"Int"},{"text":"?","kind":"text"}],"title":"candidateCount","url":"\/documentation\/firebasevertexai\/generationconfig\/candidatecount","type":"topic","role":"symbol","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/GenerationConfig/temperature":{"abstract":[{"text":"A parameter controlling the degree of randomness in token selection. A","type":"text"},{"type":"text","text":" "},{"type":"text","text":"temperature of zero is deterministic, always choosing the"},{"type":"text","text":" "},{"text":"highest-probability response. Typical values are between 0 and 1","type":"text"},{"type":"text","text":" "},{"text":"inclusive. Defaults to 0 if unspecified.","type":"text"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/temperature","fragments":[{"text":"let","kind":"keyword"},{"kind":"text","text":" "},{"text":"temperature","kind":"identifier"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Float","preciseIdentifier":"s:Sf"},{"text":"?","kind":"text"}],"type":"topic","title":"temperature","url":"\/documentation\/firebasevertexai\/generationconfig\/temperature","role":"symbol","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/GenerationConfig":{"abstract":[{"type":"text","text":"A struct defining model parameters to be used when sending generative AI"},{"text":" ","type":"text"},{"type":"text","text":"requests to the backend model."}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig","fragments":[{"text":"struct","kind":"keyword"},{"kind":"text","text":" "},{"text":"GenerationConfig","kind":"identifier"}],"navigatorTitle":[{"text":"GenerationConfig","kind":"identifier"}],"title":"GenerationConfig","url":"\/documentation\/firebasevertexai\/generationconfig","type":"topic","role":"symbol","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/GenerationConfig/responseMIMEType":{"abstract":[{"text":"Output response MIME type of the generated candidate text.","type":"text"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/GenerationConfig\/responseMIMEType","fragments":[{"text":"let","kind":"keyword"},{"kind":"text","text":" "},{"text":"responseMIMEType","kind":"identifier"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"String","preciseIdentifier":"s:SS"},{"text":"?","kind":"text"}],"type":"topic","title":"responseMIMEType","url":"\/documentation\/firebasevertexai\/generationconfig\/responsemimetype","role":"symbol","kind":"symbol"}}}
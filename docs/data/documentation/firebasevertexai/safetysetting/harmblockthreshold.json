{"abstract":[{"type":"text","text":"Block at and beyond a specified "},{"type":"reference","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","isActive":true},{"text":".","type":"text"}],"topicSections":[{"identifiers":["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/blockLowAndAbove","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/blockMediumAndAbove","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/blockNone","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/blockOnlyHigh"],"title":"Enumeration Cases"},{"identifiers":["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/init(rawValue:)"],"title":"Initializers"},{"identifiers":["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/Equatable-Implementations","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/RawRepresentable-Implementations"],"title":"Default Implementations","generated":true}],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold"]}],"relationshipsSections":[{"identifiers":["doc:\/\/FirebaseVertexAI\/SE","doc:\/\/FirebaseVertexAI\/SQ","doc:\/\/FirebaseVertexAI\/SH","doc:\/\/FirebaseVertexAI\/SY","doc:\/\/FirebaseVertexAI\/s8SendableP"],"kind":"relationships","type":"conformsTo","title":"Conforms To"}],"hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting"]]},"primaryContentSections":[{"kind":"declarations","declarations":[{"platforms":["macOS"],"languages":["swift"],"tokens":[{"text":"enum","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"HarmBlockThreshold"}]}]}],"identifier":{"url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold","interfaceLanguage":"swift"},"sections":[],"kind":"symbol","metadata":{"symbolKind":"enum","platforms":[{"introducedAt":"15.0","beta":false,"name":"iOS","unavailable":false,"deprecated":false},{"name":"macOS","introducedAt":"11.0","beta":false,"unavailable":false,"deprecated":false},{"unavailable":false,"beta":false,"deprecated":false,"name":"Mac Catalyst","introducedAt":"15.0"},{"introducedAt":"15.0","deprecated":false,"unavailable":false,"beta":false,"name":"tvOS"},{"deprecated":false,"name":"watchOS","introducedAt":"8.0","unavailable":false,"beta":false}],"fragments":[{"text":"enum","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"HarmBlockThreshold"}],"title":"SafetySetting.HarmBlockThreshold","role":"symbol","externalID":"s:16FirebaseVertexAI13SafetySettingV18HarmBlockThresholdO","modules":[{"name":"FirebaseVertexAI"}],"roleHeading":"Enumeration","navigatorTitle":[{"text":"HarmBlockThreshold","kind":"identifier"}]},"schemaVersion":{"minor":3,"major":0,"patch":0},"references":{"doc://FirebaseVertexAI/SY":{"title":"Swift.RawRepresentable","identifier":"doc:\/\/FirebaseVertexAI\/SY","type":"unresolvable"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold":{"role":"symbol","type":"topic","fragments":[{"text":"enum","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"HarmBlockThreshold"}],"url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold","navigatorTitle":[{"kind":"identifier","text":"HarmBlockThreshold"}],"abstract":[{"type":"text","text":"Block at and beyond a specified "},{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","isActive":true,"type":"reference"},{"text":".","type":"text"}],"kind":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold","title":"SafetySetting.HarmBlockThreshold"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold/RawRepresentable-Implementations":{"url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/rawrepresentable-implementations","kind":"article","abstract":[],"type":"topic","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/RawRepresentable-Implementations","title":"RawRepresentable Implementations","role":"collectionGroup"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold/blockNone":{"url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/blocknone","role":"symbol","fragments":[{"text":"case","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"blockNone"}],"type":"topic","title":"SafetySetting.HarmBlockThreshold.blockNone","abstract":[{"text":"All content will be allowed.","type":"text"}],"kind":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/blockNone"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold/init(rawValue:)":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/init(rawValue:)","abstract":[],"type":"topic","role":"symbol","url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/init(rawvalue:)","fragments":[{"text":"init","kind":"identifier"},{"text":"?(","kind":"text"},{"kind":"externalParam","text":"rawValue"},{"kind":"text","text":": "},{"text":"String","kind":"typeIdentifier","preciseIdentifier":"s:SS"},{"kind":"text","text":")"}],"title":"init(rawValue:)","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold/blockMediumAndAbove":{"kind":"symbol","fragments":[{"text":"case","kind":"keyword"},{"kind":"text","text":" "},{"text":"blockMediumAndAbove","kind":"identifier"}],"abstract":[{"type":"text","text":"Content with "},{"type":"codeVoice","code":".negligible"},{"type":"text","text":" and "},{"type":"codeVoice","code":".low"},{"text":" will be allowed.","type":"text"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/blockMediumAndAbove","title":"SafetySetting.HarmBlockThreshold.blockMediumAndAbove","role":"symbol","url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/blockmediumandabove","type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold/blockOnlyHigh":{"kind":"symbol","fragments":[{"text":"case","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"blockOnlyHigh"}],"abstract":[{"text":"Content with ","type":"text"},{"type":"codeVoice","code":".negligible"},{"type":"text","text":", "},{"type":"codeVoice","code":".low"},{"type":"text","text":", and "},{"type":"codeVoice","code":".medium"},{"type":"text","text":" will be allowed."}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/blockOnlyHigh","title":"SafetySetting.HarmBlockThreshold.blockOnlyHigh","role":"symbol","url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/blockonlyhigh","type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability":{"title":"SafetyRating.HarmProbability","navigatorTitle":[{"text":"HarmProbability","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","kind":"symbol","abstract":[{"type":"text","text":"The probability that a given model output falls under a harmful content category. This does"},{"type":"text","text":" "},{"text":"not indicate the severity of harm for a piece of content.","type":"text"}],"role":"symbol","fragments":[{"kind":"keyword","text":"enum"},{"text":" ","kind":"text"},{"text":"HarmProbability","kind":"identifier"}],"type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"kind":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","type":"topic","url":"\/documentation\/firebasevertexai","abstract":[],"title":"FirebaseVertexAI","role":"collection"},"doc://FirebaseVertexAI/SQ":{"type":"unresolvable","identifier":"doc:\/\/FirebaseVertexAI\/SQ","title":"Swift.Equatable"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold/blockLowAndAbove":{"kind":"symbol","fragments":[{"kind":"keyword","text":"case"},{"text":" ","kind":"text"},{"kind":"identifier","text":"blockLowAndAbove"}],"abstract":[],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/blockLowAndAbove","title":"SafetySetting.HarmBlockThreshold.blockLowAndAbove","role":"symbol","url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/blocklowandabove","type":"topic"},"doc://FirebaseVertexAI/s8SendableP":{"identifier":"doc:\/\/FirebaseVertexAI\/s8SendableP","type":"unresolvable","title":"Swift.Sendable"},"doc://FirebaseVertexAI/SE":{"identifier":"doc:\/\/FirebaseVertexAI\/SE","type":"unresolvable","title":"Swift.Encodable"},"doc://FirebaseVertexAI/SH":{"identifier":"doc:\/\/FirebaseVertexAI\/SH","type":"unresolvable","title":"Swift.Hashable"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold/Equatable-Implementations":{"kind":"article","abstract":[],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/Equatable-Implementations","title":"Equatable Implementations","role":"collectionGroup","url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/equatable-implementations","type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting":{"role":"symbol","type":"topic","fragments":[{"kind":"keyword","text":"struct"},{"text":" ","kind":"text"},{"kind":"identifier","text":"SafetySetting"}],"url":"\/documentation\/firebasevertexai\/safetysetting","navigatorTitle":[{"text":"SafetySetting","kind":"identifier"}],"abstract":[{"text":"A type used to specify a threshold for harmful content, beyond which the model will return a","type":"text"},{"type":"text","text":" "},{"type":"text","text":"fallback response instead of generated content."}],"kind":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting","title":"SafetySetting"}}}
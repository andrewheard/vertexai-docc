{"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/firebasevertexai\/safetysetting\/blockthreshold\/blockmediumandabove"]}],"abstract":[{"text":"Content with ","type":"text"},{"type":"codeVoice","code":".negligible"},{"text":" and ","type":"text"},{"type":"codeVoice","code":".low"},{"text":" will be allowed.","type":"text"}],"metadata":{"title":"SafetySetting.BlockThreshold.blockMediumAndAbove","modules":[{"name":"FirebaseVertexAI"}],"symbolKind":"case","platforms":[{"introducedAt":"15.0","deprecated":false,"name":"iOS","unavailable":false,"beta":false},{"unavailable":false,"name":"macOS","deprecated":false,"beta":false,"introducedAt":"11.0"},{"unavailable":false,"deprecated":false,"beta":false,"name":"Mac Catalyst","introducedAt":"15.0"},{"name":"tvOS","deprecated":false,"unavailable":false,"beta":false,"introducedAt":"15.0"},{"introducedAt":"8.0","deprecated":false,"unavailable":false,"beta":false,"name":"watchOS"}],"fragments":[{"kind":"keyword","text":"case"},{"kind":"text","text":" "},{"kind":"identifier","text":"blockMediumAndAbove"}],"role":"symbol","externalID":"s:16FirebaseVertexAI13SafetySettingV14BlockThresholdO19blockMediumAndAboveyA2EmF","roleHeading":"Case"},"schemaVersion":{"major":0,"minor":3,"patch":0},"hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/BlockThreshold"]]},"primaryContentSections":[{"kind":"declarations","declarations":[{"platforms":["macOS"],"tokens":[{"kind":"keyword","text":"case"},{"kind":"text","text":" "},{"kind":"identifier","text":"blockMediumAndAbove"}],"languages":["swift"]}]}],"sections":[],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/BlockThreshold\/blockMediumAndAbove"},"kind":"symbol","references":{"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting":{"kind":"symbol","fragments":[{"kind":"keyword","text":"struct"},{"text":" ","kind":"text"},{"text":"SafetySetting","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetysetting","title":"SafetySetting","role":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting","abstract":[{"type":"text","text":"A type used to specify a threshold for harmful content, beyond which the model will return a"},{"text":" ","type":"text"},{"text":"fallback response instead of generated content.","type":"text"}],"navigatorTitle":[{"text":"SafetySetting","kind":"identifier"}],"type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/BlockThreshold/blockMediumAndAbove":{"url":"\/documentation\/firebasevertexai\/safetysetting\/blockthreshold\/blockmediumandabove","abstract":[{"type":"text","text":"Content with "},{"code":".negligible","type":"codeVoice"},{"text":" and ","type":"text"},{"type":"codeVoice","code":".low"},{"text":" will be allowed.","type":"text"}],"title":"SafetySetting.BlockThreshold.blockMediumAndAbove","kind":"symbol","role":"symbol","fragments":[{"kind":"keyword","text":"case"},{"kind":"text","text":" "},{"kind":"identifier","text":"blockMediumAndAbove"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/BlockThreshold\/blockMediumAndAbove","type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/BlockThreshold":{"kind":"symbol","fragments":[{"kind":"keyword","text":"enum"},{"text":" ","kind":"text"},{"text":"BlockThreshold","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetysetting\/blockthreshold","title":"SafetySetting.BlockThreshold","role":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/BlockThreshold","abstract":[{"text":"Block at and beyond a specified ","type":"text"},{"isActive":true,"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","type":"reference"},{"text":".","type":"text"}],"navigatorTitle":[{"kind":"identifier","text":"BlockThreshold"}],"type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"abstract":[],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","role":"collection","url":"\/documentation\/firebasevertexai","type":"topic","title":"FirebaseVertexAI","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability":{"kind":"symbol","fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"HarmProbability","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability","title":"SafetyRating.HarmProbability","role":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","abstract":[{"type":"text","text":"The probability that a given model output falls under a harmful content category. This does"},{"text":" ","type":"text"},{"text":"not indicate the severity of harm for a piece of content.","type":"text"}],"navigatorTitle":[{"kind":"identifier","text":"HarmProbability"}],"type":"topic"}}}
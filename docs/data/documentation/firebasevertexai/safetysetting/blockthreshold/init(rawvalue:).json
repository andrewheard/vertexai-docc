{"sections":[],"variants":[{"paths":["\/documentation\/firebasevertexai\/safetysetting\/blockthreshold\/init(rawvalue:)"],"traits":[{"interfaceLanguage":"swift"}]}],"primaryContentSections":[{"kind":"declarations","declarations":[{"tokens":[{"text":"init","kind":"keyword"},{"kind":"text","text":"?("},{"kind":"externalParam","text":"rawValue"},{"kind":"text","text":": "},{"preciseIdentifier":"s:SS","kind":"typeIdentifier","text":"String"},{"text":")","kind":"text"}],"platforms":["macOS"],"languages":["swift"]}]}],"schemaVersion":{"patch":0,"minor":3,"major":0},"hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/BlockThreshold"]]},"kind":"symbol","metadata":{"platforms":[{"deprecated":false,"unavailable":false,"name":"iOS","introducedAt":"15.0","beta":false},{"name":"macOS","beta":false,"unavailable":false,"deprecated":false,"introducedAt":"11.0"},{"deprecated":false,"unavailable":false,"beta":false,"name":"Mac Catalyst","introducedAt":"15.0"},{"name":"tvOS","introducedAt":"15.0","unavailable":false,"beta":false,"deprecated":false},{"name":"watchOS","introducedAt":"8.0","deprecated":false,"unavailable":false,"beta":false}],"externalID":"s:16FirebaseVertexAI13SafetySettingV14BlockThresholdO8rawValueAESgSS_tcfc","title":"init(rawValue:)","modules":[{"name":"FirebaseVertexAI"}],"symbolKind":"init","roleHeading":"Initializer","role":"symbol","fragments":[{"text":"init","kind":"identifier"},{"kind":"text","text":"?("},{"text":"rawValue","kind":"externalParam"},{"kind":"text","text":": "},{"text":"String","kind":"typeIdentifier","preciseIdentifier":"s:SS"},{"kind":"text","text":")"}]},"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/BlockThreshold\/init(rawValue:)"},"abstract":[{"text":"Inherited from ","type":"text"},{"type":"codeVoice","code":"RawRepresentable.init(rawValue:)"},{"type":"text","text":"."}],"references":{"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"abstract":[],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","role":"collection","url":"\/documentation\/firebasevertexai","type":"topic","title":"FirebaseVertexAI","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/BlockThreshold":{"kind":"symbol","fragments":[{"kind":"keyword","text":"enum"},{"text":" ","kind":"text"},{"text":"BlockThreshold","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetysetting\/blockthreshold","title":"SafetySetting.BlockThreshold","role":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/BlockThreshold","abstract":[{"text":"Block at and beyond a specified ","type":"text"},{"isActive":true,"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","type":"reference"},{"text":".","type":"text"}],"navigatorTitle":[{"kind":"identifier","text":"BlockThreshold"}],"type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/BlockThreshold/init(rawValue:)":{"abstract":[],"title":"init(rawValue:)","type":"topic","fragments":[{"kind":"identifier","text":"init"},{"text":"?(","kind":"text"},{"text":"rawValue","kind":"externalParam"},{"kind":"text","text":": "},{"preciseIdentifier":"s:SS","kind":"typeIdentifier","text":"String"},{"text":")","kind":"text"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/BlockThreshold\/init(rawValue:)","kind":"symbol","role":"symbol","url":"\/documentation\/firebasevertexai\/safetysetting\/blockthreshold\/init(rawvalue:)"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting":{"kind":"symbol","fragments":[{"kind":"keyword","text":"struct"},{"text":" ","kind":"text"},{"text":"SafetySetting","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetysetting","title":"SafetySetting","role":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting","abstract":[{"type":"text","text":"A type used to specify a threshold for harmful content, beyond which the model will return a"},{"text":" ","type":"text"},{"text":"fallback response instead of generated content.","type":"text"}],"navigatorTitle":[{"text":"SafetySetting","kind":"identifier"}],"type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability":{"kind":"symbol","fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"HarmProbability","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability","title":"SafetyRating.HarmProbability","role":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","abstract":[{"type":"text","text":"The probability that a given model output falls under a harmful content category. This does"},{"text":" ","type":"text"},{"text":"not indicate the severity of harm for a piece of content.","type":"text"}],"navigatorTitle":[{"kind":"identifier","text":"HarmProbability"}],"type":"topic"}}}
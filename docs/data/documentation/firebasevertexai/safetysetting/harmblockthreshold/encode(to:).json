{"metadata":{"title":"encode(to:)","role":"symbol","fragments":[{"kind":"keyword","text":"func"},{"text":" ","kind":"text"},{"kind":"identifier","text":"encode"},{"kind":"text","text":"("},{"text":"to","kind":"externalParam"},{"text":": ","kind":"text"},{"preciseIdentifier":"s:s7EncoderP","text":"Encoder","kind":"typeIdentifier"},{"text":") ","kind":"text"},{"text":"throws","kind":"keyword"}],"extendedModule":"Swift","externalID":"s:SYsSERzSS8RawValueSYRtzrlE6encode2toys7Encoder_p_tKF::SYNTHESIZED::s:16FirebaseVertexAI13SafetySettingV18HarmBlockThresholdO","conformance":{"conformancePrefix":[{"type":"text","text":"Conforms when"}],"availabilityPrefix":[{"text":"Available when","type":"text"}],"constraints":[{"type":"codeVoice","code":"Self"},{"type":"text","text":" conforms to "},{"type":"codeVoice","code":"Encodable"},{"type":"text","text":" and "},{"type":"codeVoice","code":"RawValue"},{"type":"text","text":" is "},{"type":"codeVoice","code":"String"},{"type":"text","text":"."}]},"modules":[{"name":"FirebaseVertexAI","relatedModules":["Swift"]}],"roleHeading":"Instance Method","symbolKind":"method"},"sections":[],"kind":"symbol","schemaVersion":{"major":0,"minor":3,"patch":0},"abstract":[{"text":"Inherited from ","type":"text"},{"type":"codeVoice","code":"RawRepresentable.encode(to:)"},{"text":".","type":"text"}],"variants":[{"paths":["\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/encode(to:)"],"traits":[{"interfaceLanguage":"swift"}]}],"primaryContentSections":[{"kind":"declarations","declarations":[{"platforms":["macOS"],"languages":["swift"],"tokens":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"encode"},{"kind":"text","text":"("},{"kind":"externalParam","text":"to"},{"text":" ","kind":"text"},{"text":"encoder","kind":"internalParam"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","text":"Encoder","preciseIdentifier":"s:s7EncoderP"},{"text":") ","kind":"text"},{"kind":"keyword","text":"throws"}]}]}],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/encode(to:)"},"hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/RawRepresentable-Implementations"]]},"references":{"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","kind":"symbol","abstract":[{"type":"text","text":"The probability that a given model output falls under a harmful content category. This does"},{"type":"text","text":" "},{"text":"not indicate the severity of harm for a piece of content.","type":"text"}],"navigatorTitle":[{"text":"HarmProbability","kind":"identifier"}],"fragments":[{"text":"enum","kind":"keyword"},{"kind":"text","text":" "},{"text":"HarmProbability","kind":"identifier"}],"role":"symbol","url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability","type":"topic","title":"SafetyRating.HarmProbability"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold","type":"topic","fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"HarmBlockThreshold","kind":"identifier"}],"title":"SafetySetting.HarmBlockThreshold","url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold","abstract":[{"text":"Block at and beyond a specified ","type":"text"},{"isActive":true,"type":"reference","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability"},{"type":"text","text":"."}],"navigatorTitle":[{"text":"HarmBlockThreshold","kind":"identifier"}],"role":"symbol","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","abstract":[],"url":"\/documentation\/firebasevertexai","role":"collection","type":"topic","title":"FirebaseVertexAI","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold/RawRepresentable-Implementations":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/RawRepresentable-Implementations","type":"topic","url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/rawrepresentable-implementations","kind":"article","abstract":[],"role":"collectionGroup","title":"RawRepresentable Implementations"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting","type":"topic","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"SafetySetting","kind":"identifier"}],"title":"SafetySetting","url":"\/documentation\/firebasevertexai\/safetysetting","abstract":[{"type":"text","text":"A type used to specify a threshold for harmful content, beyond which the model will return a"},{"type":"text","text":" "},{"type":"text","text":"fallback response instead of generated content."}],"navigatorTitle":[{"text":"SafetySetting","kind":"identifier"}],"role":"symbol","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold/encode(to:)":{"title":"encode(to:)","kind":"symbol","abstract":[],"fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"text":"encode","kind":"identifier"},{"text":"(","kind":"text"},{"text":"to","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"Encoder","kind":"typeIdentifier","preciseIdentifier":"s:s7EncoderP"},{"kind":"text","text":") "},{"kind":"keyword","text":"throws"}],"type":"topic","url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/encode(to:)","role":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/encode(to:)","conformance":{"availabilityPrefix":[{"type":"text","text":"Available when"}],"conformancePrefix":[{"type":"text","text":"Conforms when"}],"constraints":[{"type":"codeVoice","code":"Self"},{"text":" conforms to ","type":"text"},{"type":"codeVoice","code":"Encodable"},{"text":" and ","type":"text"},{"type":"codeVoice","code":"RawValue"},{"text":" is ","type":"text"},{"type":"codeVoice","code":"String"},{"type":"text","text":"."}]}}}}
{"abstract":[{"text":"Inherited from ","type":"text"},{"code":"RawRepresentable.init(rawValue:)","type":"codeVoice"},{"text":".","type":"text"}],"sections":[],"kind":"symbol","schemaVersion":{"major":0,"minor":3,"patch":0},"metadata":{"modules":[{"name":"FirebaseVertexAI"}],"title":"init(rawValue:)","role":"symbol","externalID":"s:16FirebaseVertexAI13SafetySettingV18HarmBlockThresholdO8rawValueAESgSS_tcfc","symbolKind":"init","platforms":[{"beta":false,"introducedAt":"15.0","deprecated":false,"unavailable":false,"name":"iOS"},{"beta":false,"deprecated":false,"introducedAt":"11.0","unavailable":false,"name":"macOS"},{"unavailable":false,"name":"Mac Catalyst","introducedAt":"15.0","beta":false,"deprecated":false},{"name":"tvOS","unavailable":false,"deprecated":false,"beta":false,"introducedAt":"15.0"},{"unavailable":false,"beta":false,"deprecated":false,"introducedAt":"8.0","name":"watchOS"}],"fragments":[{"kind":"identifier","text":"init"},{"kind":"text","text":"?("},{"kind":"externalParam","text":"rawValue"},{"text":": ","kind":"text"},{"text":"String","kind":"typeIdentifier","preciseIdentifier":"s:SS"},{"text":")","kind":"text"}],"roleHeading":"Initializer"},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/init(rawvalue:)"]}],"primaryContentSections":[{"kind":"declarations","declarations":[{"platforms":["macOS"],"languages":["swift"],"tokens":[{"text":"init","kind":"keyword"},{"text":"?(","kind":"text"},{"text":"rawValue","kind":"externalParam"},{"kind":"text","text":": "},{"text":"String","kind":"typeIdentifier","preciseIdentifier":"s:SS"},{"text":")","kind":"text"}]}]}],"identifier":{"url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/init(rawValue:)","interfaceLanguage":"swift"},"hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold"]]},"references":{"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold","type":"topic","fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"HarmBlockThreshold","kind":"identifier"}],"title":"SafetySetting.HarmBlockThreshold","url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold","abstract":[{"text":"Block at and beyond a specified ","type":"text"},{"isActive":true,"type":"reference","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability"},{"type":"text","text":"."}],"navigatorTitle":[{"text":"HarmBlockThreshold","kind":"identifier"}],"role":"symbol","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","abstract":[],"url":"\/documentation\/firebasevertexai","role":"collection","type":"topic","title":"FirebaseVertexAI","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting","type":"topic","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"SafetySetting","kind":"identifier"}],"title":"SafetySetting","url":"\/documentation\/firebasevertexai\/safetysetting","abstract":[{"type":"text","text":"A type used to specify a threshold for harmful content, beyond which the model will return a"},{"type":"text","text":" "},{"type":"text","text":"fallback response instead of generated content."}],"navigatorTitle":[{"text":"SafetySetting","kind":"identifier"}],"role":"symbol","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold/init(rawValue:)":{"fragments":[{"text":"init","kind":"identifier"},{"text":"?(","kind":"text"},{"kind":"externalParam","text":"rawValue"},{"text":": ","kind":"text"},{"text":"String","kind":"typeIdentifier","preciseIdentifier":"s:SS"},{"kind":"text","text":")"}],"type":"topic","url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/init(rawvalue:)","title":"init(rawValue:)","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/init(rawValue:)","kind":"symbol","abstract":[],"role":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","kind":"symbol","abstract":[{"type":"text","text":"The probability that a given model output falls under a harmful content category. This does"},{"type":"text","text":" "},{"text":"not indicate the severity of harm for a piece of content.","type":"text"}],"navigatorTitle":[{"text":"HarmProbability","kind":"identifier"}],"fragments":[{"text":"enum","kind":"keyword"},{"kind":"text","text":" "},{"text":"HarmProbability","kind":"identifier"}],"role":"symbol","url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability","type":"topic","title":"SafetyRating.HarmProbability"}}}
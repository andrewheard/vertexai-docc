{"kind":"symbol","primaryContentSections":[{"declarations":[{"platforms":["macOS"],"tokens":[{"text":"init","kind":"keyword"},{"text":"?(","kind":"text"},{"text":"rawValue","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"String","preciseIdentifier":"s:SS","kind":"typeIdentifier"},{"kind":"text","text":")"}],"languages":["swift"]}],"kind":"declarations"}],"identifier":{"url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/init(rawValue:)","interfaceLanguage":"swift"},"schemaVersion":{"minor":3,"major":0,"patch":0},"sections":[],"abstract":[{"text":"Inherited from ","type":"text"},{"type":"codeVoice","code":"RawRepresentable.init(rawValue:)"},{"text":".","type":"text"}],"hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold"]]},"variants":[{"paths":["\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/init(rawvalue:)"],"traits":[{"interfaceLanguage":"swift"}]}],"metadata":{"modules":[{"name":"FirebaseVertexAI"}],"platforms":[{"deprecated":false,"unavailable":false,"beta":false,"introducedAt":"15.0","name":"iOS"},{"name":"macOS","deprecated":false,"unavailable":false,"introducedAt":"11.0","beta":false},{"beta":false,"deprecated":false,"name":"Mac Catalyst","unavailable":false,"introducedAt":"15.0"},{"introducedAt":"15.0","unavailable":false,"deprecated":false,"beta":false,"name":"tvOS"},{"introducedAt":"8.0","unavailable":false,"beta":false,"deprecated":false,"name":"watchOS"}],"role":"symbol","title":"init(rawValue:)","externalID":"s:16FirebaseVertexAI13SafetySettingV18HarmBlockThresholdO8rawValueAESgSS_tcfc","symbolKind":"init","roleHeading":"Initializer","fragments":[{"text":"init","kind":"identifier"},{"kind":"text","text":"?("},{"kind":"externalParam","text":"rawValue"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"s:SS","text":"String"},{"text":")","kind":"text"}]},"references":{"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold":{"abstract":[{"text":"Block at and beyond a specified ","type":"text"},{"isActive":true,"type":"reference","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability"},{"text":".","type":"text"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold","url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold","fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"HarmBlockThreshold","kind":"identifier"}],"kind":"symbol","navigatorTitle":[{"kind":"identifier","text":"HarmBlockThreshold"}],"role":"symbol","title":"SafetySetting.HarmBlockThreshold","type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting":{"navigatorTitle":[{"kind":"identifier","text":"SafetySetting"}],"url":"\/documentation\/firebasevertexai\/safetysetting","fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"kind":"identifier","text":"SafetySetting"}],"type":"topic","role":"symbol","kind":"symbol","abstract":[{"text":"A type used to specify a threshold for harmful content, beyond which the model will return a","type":"text"},{"type":"text","text":" "},{"type":"text","text":"fallback response instead of generated content."}],"title":"SafetySetting","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","kind":"symbol","abstract":[],"title":"FirebaseVertexAI","role":"collection","type":"topic","url":"\/documentation\/firebasevertexai"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold/init(rawValue:)":{"abstract":[],"kind":"symbol","url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/init(rawvalue:)","type":"topic","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/init(rawValue:)","role":"symbol","fragments":[{"text":"init","kind":"identifier"},{"kind":"text","text":"?("},{"text":"rawValue","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"String","preciseIdentifier":"s:SS","kind":"typeIdentifier"},{"kind":"text","text":")"}],"title":"init(rawValue:)"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability":{"fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"HarmProbability","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability","title":"SafetyRating.HarmProbability","abstract":[{"type":"text","text":"The probability that a given model output falls under a harmful content category. This does"},{"type":"text","text":" "},{"type":"text","text":"not indicate the severity of harm for a piece of content."}],"type":"topic","kind":"symbol","role":"symbol","navigatorTitle":[{"text":"HarmProbability","kind":"identifier"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability"}}}
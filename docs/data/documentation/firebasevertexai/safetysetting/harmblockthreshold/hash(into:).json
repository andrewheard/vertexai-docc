{"abstract":[{"text":"Inherited from ","type":"text"},{"code":"RawRepresentable.hash(into:)","type":"codeVoice"},{"type":"text","text":"."}],"sections":[],"primaryContentSections":[{"kind":"declarations","declarations":[{"tokens":[{"text":"func","kind":"keyword"},{"text":" ","kind":"text"},{"text":"hash","kind":"identifier"},{"text":"(","kind":"text"},{"text":"into","kind":"externalParam"},{"text":" ","kind":"text"},{"kind":"internalParam","text":"hasher"},{"text":": ","kind":"text"},{"kind":"keyword","text":"inout"},{"kind":"text","text":" "},{"text":"Hasher","kind":"typeIdentifier","preciseIdentifier":"s:s6HasherV"},{"text":")","kind":"text"}],"platforms":["macOS"],"languages":["swift"]}]}],"metadata":{"conformance":{"constraints":[{"type":"codeVoice","code":"Self"},{"text":" conforms to ","type":"text"},{"code":"Hashable","type":"codeVoice"},{"type":"text","text":" and "},{"type":"codeVoice","code":"RawValue"},{"type":"text","text":" conforms to "},{"code":"Hashable","type":"codeVoice"},{"text":".","type":"text"}],"availabilityPrefix":[{"text":"Available when","type":"text"}],"conformancePrefix":[{"text":"Conforms when","type":"text"}]},"symbolKind":"method","externalID":"s:SYsSHRzSH8RawValueSYRpzrlE4hash4intoys6HasherVz_tF::SYNTHESIZED::s:16FirebaseVertexAI13SafetySettingV18HarmBlockThresholdO","modules":[{"name":"FirebaseVertexAI","relatedModules":["Swift"]}],"roleHeading":"Instance Method","role":"symbol","extendedModule":"Swift","title":"hash(into:)","fragments":[{"text":"func","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"hash"},{"kind":"text","text":"("},{"text":"into","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"inout","kind":"keyword"},{"text":" ","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"s:s6HasherV","text":"Hasher"},{"kind":"text","text":")"}]},"variants":[{"paths":["\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/hash(into:)"],"traits":[{"interfaceLanguage":"swift"}]}],"identifier":{"url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/hash(into:)","interfaceLanguage":"swift"},"kind":"symbol","schemaVersion":{"major":0,"minor":3,"patch":0},"hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/RawRepresentable-Implementations"]]},"references":{"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold/RawRepresentable-Implementations":{"kind":"article","role":"collectionGroup","title":"RawRepresentable Implementations","abstract":[],"type":"topic","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/RawRepresentable-Implementations","url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/rawrepresentable-implementations"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability":{"fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"HarmProbability","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability","title":"SafetyRating.HarmProbability","abstract":[{"type":"text","text":"The probability that a given model output falls under a harmful content category. This does"},{"type":"text","text":" "},{"type":"text","text":"not indicate the severity of harm for a piece of content."}],"type":"topic","kind":"symbol","role":"symbol","navigatorTitle":[{"text":"HarmProbability","kind":"identifier"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","kind":"symbol","abstract":[],"title":"FirebaseVertexAI","role":"collection","type":"topic","url":"\/documentation\/firebasevertexai"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold/hash(into:)":{"abstract":[],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/hash(into:)","url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/hash(into:)","fragments":[{"text":"func","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"hash"},{"text":"(","kind":"text"},{"text":"into","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"inout","kind":"keyword"},{"kind":"text","text":" "},{"preciseIdentifier":"s:s6HasherV","kind":"typeIdentifier","text":"Hasher"},{"kind":"text","text":")"}],"kind":"symbol","conformance":{"constraints":[{"code":"Self","type":"codeVoice"},{"text":" conforms to ","type":"text"},{"code":"Hashable","type":"codeVoice"},{"type":"text","text":" and "},{"type":"codeVoice","code":"RawValue"},{"type":"text","text":" conforms to "},{"code":"Hashable","type":"codeVoice"},{"text":".","type":"text"}],"conformancePrefix":[{"text":"Conforms when","type":"text"}],"availabilityPrefix":[{"text":"Available when","type":"text"}]},"role":"symbol","title":"hash(into:)","type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold":{"abstract":[{"text":"Block at and beyond a specified ","type":"text"},{"isActive":true,"type":"reference","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability"},{"text":".","type":"text"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold","url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold","fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"HarmBlockThreshold","kind":"identifier"}],"kind":"symbol","navigatorTitle":[{"kind":"identifier","text":"HarmBlockThreshold"}],"role":"symbol","title":"SafetySetting.HarmBlockThreshold","type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting":{"navigatorTitle":[{"kind":"identifier","text":"SafetySetting"}],"url":"\/documentation\/firebasevertexai\/safetysetting","fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"kind":"identifier","text":"SafetySetting"}],"type":"topic","role":"symbol","kind":"symbol","abstract":[{"text":"A type used to specify a threshold for harmful content, beyond which the model will return a","type":"text"},{"type":"text","text":" "},{"type":"text","text":"fallback response instead of generated content."}],"title":"SafetySetting","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting"}}}
{"kind":"symbol","identifier":{"interfaceLanguage":"swift","url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/hash(into:)"},"schemaVersion":{"patch":0,"minor":3,"major":0},"metadata":{"roleHeading":"Instance Method","role":"symbol","modules":[{"relatedModules":["Swift"],"name":"FirebaseVertexAI"}],"title":"hash(into:)","fragments":[{"text":"func","kind":"keyword"},{"kind":"text","text":" "},{"text":"hash","kind":"identifier"},{"kind":"text","text":"("},{"text":"into","kind":"externalParam"},{"kind":"text","text":": "},{"kind":"keyword","text":"inout"},{"kind":"text","text":" "},{"text":"Hasher","kind":"typeIdentifier","preciseIdentifier":"s:s6HasherV"},{"kind":"text","text":")"}],"conformance":{"constraints":[{"type":"codeVoice","code":"Self"},{"type":"text","text":" conforms to "},{"type":"codeVoice","code":"Hashable"},{"type":"text","text":" and "},{"type":"codeVoice","code":"RawValue"},{"text":" conforms to ","type":"text"},{"code":"Hashable","type":"codeVoice"},{"type":"text","text":"."}],"availabilityPrefix":[{"text":"Available when","type":"text"}],"conformancePrefix":[{"type":"text","text":"Conforms when"}]},"extendedModule":"Swift","externalID":"s:SYsSHRzSH8RawValueSYRpzrlE4hash4intoys6HasherVz_tF::SYNTHESIZED::s:16FirebaseVertexAI13SafetySettingV18HarmBlockThresholdO","symbolKind":"method"},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/hash(into:)"]}],"hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/RawRepresentable-Implementations"]]},"abstract":[{"type":"text","text":"Inherited from "},{"type":"codeVoice","code":"RawRepresentable.hash(into:)"},{"type":"text","text":"."}],"sections":[],"primaryContentSections":[{"kind":"declarations","declarations":[{"languages":["swift"],"tokens":[{"text":"func","kind":"keyword"},{"text":" ","kind":"text"},{"text":"hash","kind":"identifier"},{"text":"(","kind":"text"},{"text":"into","kind":"externalParam"},{"kind":"text","text":" "},{"text":"hasher","kind":"internalParam"},{"text":": ","kind":"text"},{"kind":"keyword","text":"inout"},{"kind":"text","text":" "},{"preciseIdentifier":"s:s6HasherV","text":"Hasher","kind":"typeIdentifier"},{"text":")","kind":"text"}],"platforms":["macOS"]}]}],"references":{"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability":{"title":"SafetyRating.HarmProbability","navigatorTitle":[{"text":"HarmProbability","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","kind":"symbol","abstract":[{"type":"text","text":"The probability that a given model output falls under a harmful content category. This does"},{"type":"text","text":" "},{"text":"not indicate the severity of harm for a piece of content.","type":"text"}],"role":"symbol","fragments":[{"kind":"keyword","text":"enum"},{"text":" ","kind":"text"},{"text":"HarmProbability","kind":"identifier"}],"type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold/hash(into:)":{"abstract":[],"title":"hash(into:)","kind":"symbol","url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/hash(into:)","role":"symbol","conformance":{"conformancePrefix":[{"type":"text","text":"Conforms when"}],"constraints":[{"type":"codeVoice","code":"Self"},{"type":"text","text":" conforms to "},{"code":"Hashable","type":"codeVoice"},{"text":" and ","type":"text"},{"type":"codeVoice","code":"RawValue"},{"text":" conforms to ","type":"text"},{"type":"codeVoice","code":"Hashable"},{"text":".","type":"text"}],"availabilityPrefix":[{"type":"text","text":"Available when"}]},"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/hash(into:)","fragments":[{"kind":"keyword","text":"func"},{"text":" ","kind":"text"},{"text":"hash","kind":"identifier"},{"kind":"text","text":"("},{"kind":"externalParam","text":"into"},{"kind":"text","text":": "},{"text":"inout","kind":"keyword"},{"text":" ","kind":"text"},{"preciseIdentifier":"s:s6HasherV","text":"Hasher","kind":"typeIdentifier"},{"text":")","kind":"text"}],"type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting":{"role":"symbol","type":"topic","fragments":[{"kind":"keyword","text":"struct"},{"text":" ","kind":"text"},{"kind":"identifier","text":"SafetySetting"}],"url":"\/documentation\/firebasevertexai\/safetysetting","navigatorTitle":[{"text":"SafetySetting","kind":"identifier"}],"abstract":[{"text":"A type used to specify a threshold for harmful content, beyond which the model will return a","type":"text"},{"type":"text","text":" "},{"type":"text","text":"fallback response instead of generated content."}],"kind":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting","title":"SafetySetting"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold":{"role":"symbol","type":"topic","fragments":[{"text":"enum","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"HarmBlockThreshold"}],"url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold","navigatorTitle":[{"kind":"identifier","text":"HarmBlockThreshold"}],"abstract":[{"type":"text","text":"Block at and beyond a specified "},{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","isActive":true,"type":"reference"},{"text":".","type":"text"}],"kind":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold","title":"SafetySetting.HarmBlockThreshold"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold/RawRepresentable-Implementations":{"url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold\/rawrepresentable-implementations","kind":"article","abstract":[],"type":"topic","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold\/RawRepresentable-Implementations","title":"RawRepresentable Implementations","role":"collectionGroup"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"kind":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","type":"topic","url":"\/documentation\/firebasevertexai","abstract":[],"title":"FirebaseVertexAI","role":"collection"}}}
{"schemaVersion":{"minor":3,"major":0,"patch":0},"metadata":{"platforms":[{"introducedAt":"15.0","unavailable":false,"beta":false,"deprecated":false,"name":"iOS"},{"unavailable":false,"deprecated":false,"introducedAt":"11.0","name":"macOS","beta":false},{"beta":false,"name":"Mac Catalyst","deprecated":false,"unavailable":false,"introducedAt":"15.0"},{"beta":false,"introducedAt":"15.0","deprecated":false,"name":"tvOS","unavailable":false},{"unavailable":false,"introducedAt":"8.0","name":"watchOS","deprecated":false,"beta":false}],"modules":[{"name":"FirebaseVertexAI"}],"roleHeading":"Initializer","externalID":"s:16FirebaseVertexAI12SafetyRatingV8category11probabilityAcA12HarmCategoryO_AC0H11ProbabilityOtcfc","role":"symbol","symbolKind":"init","fragments":[{"kind":"identifier","text":"init"},{"kind":"text","text":"("},{"kind":"externalParam","text":"category"},{"text":": ","kind":"text"},{"preciseIdentifier":"s:16FirebaseVertexAI12HarmCategoryO","text":"HarmCategory","kind":"typeIdentifier"},{"kind":"text","text":", "},{"kind":"externalParam","text":"probability"},{"kind":"text","text":": "},{"text":"SafetyRating","preciseIdentifier":"s:16FirebaseVertexAI12SafetyRatingV","kind":"typeIdentifier"},{"text":".","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"s:16FirebaseVertexAI12SafetyRatingV15HarmProbabilityO","text":"HarmProbability"},{"kind":"text","text":")"}],"title":"init(category:probability:)"},"hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating"]]},"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/init(category:probability:)"},"kind":"symbol","sections":[],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/firebasevertexai\/safetyrating\/init(category:probability:)"]}],"primaryContentSections":[{"kind":"declarations","declarations":[{"platforms":["macOS"],"languages":["swift"],"tokens":[{"kind":"keyword","text":"init"},{"text":"(","kind":"text"},{"text":"category","kind":"externalParam"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"s:16FirebaseVertexAI12HarmCategoryO","text":"HarmCategory","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/HarmCategory"},{"text":", ","kind":"text"},{"text":"probability","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"SafetyRating","kind":"typeIdentifier","preciseIdentifier":"s:16FirebaseVertexAI12SafetyRatingV","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating"},{"text":".","kind":"text"},{"preciseIdentifier":"s:16FirebaseVertexAI12SafetyRatingV15HarmProbabilityO","kind":"typeIdentifier","text":"HarmProbability","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability"},{"text":")","kind":"text"}]}]}],"abstract":[{"type":"text","text":"Initializes a new "},{"type":"codeVoice","code":"SafetyRating"},{"text":" instance with the given category and probability.","type":"text"},{"type":"text","text":" "},{"type":"text","text":"Use this initializer for SwiftUI previews or tests."}],"references":{"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/HarmCategory":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/HarmCategory","kind":"symbol","abstract":[{"type":"text","text":"Categories describing the potential harm a piece of content may pose."}],"title":"HarmCategory","type":"topic","fragments":[{"kind":"keyword","text":"enum"},{"text":" ","kind":"text"},{"text":"HarmCategory","kind":"identifier"}],"role":"symbol","url":"\/documentation\/firebasevertexai\/harmcategory","navigatorTitle":[{"kind":"identifier","text":"HarmCategory"}]},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability":{"title":"SafetyRating.HarmProbability","navigatorTitle":[{"text":"HarmProbability","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","kind":"symbol","abstract":[{"type":"text","text":"The probability that a given model output falls under a harmful content category. This does"},{"type":"text","text":" "},{"text":"not indicate the severity of harm for a piece of content.","type":"text"}],"role":"symbol","fragments":[{"kind":"keyword","text":"enum"},{"text":" ","kind":"text"},{"text":"HarmProbability","kind":"identifier"}],"type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/init(category:probability:)":{"type":"topic","role":"symbol","kind":"symbol","fragments":[{"text":"init","kind":"identifier"},{"kind":"text","text":"("},{"text":"category","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"HarmCategory","kind":"typeIdentifier","preciseIdentifier":"s:16FirebaseVertexAI12HarmCategoryO"},{"text":", ","kind":"text"},{"text":"probability","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"SafetyRating","kind":"typeIdentifier","preciseIdentifier":"s:16FirebaseVertexAI12SafetyRatingV"},{"text":".","kind":"text"},{"kind":"typeIdentifier","text":"HarmProbability","preciseIdentifier":"s:16FirebaseVertexAI12SafetyRatingV15HarmProbabilityO"},{"kind":"text","text":")"}],"abstract":[{"type":"text","text":"Initializes a new "},{"type":"codeVoice","code":"SafetyRating"},{"text":" instance with the given category and probability.","type":"text"},{"type":"text","text":" "},{"type":"text","text":"Use this initializer for SwiftUI previews or tests."}],"title":"init(category:probability:)","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/init(category:probability:)","url":"\/documentation\/firebasevertexai\/safetyrating\/init(category:probability:)"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"kind":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","type":"topic","url":"\/documentation\/firebasevertexai","abstract":[],"title":"FirebaseVertexAI","role":"collection"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating":{"type":"topic","navigatorTitle":[{"kind":"identifier","text":"SafetyRating"}],"url":"\/documentation\/firebasevertexai\/safetyrating","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating","kind":"symbol","abstract":[{"type":"text","text":"A type defining potentially harmful media categories and their model-assigned ratings. A value"},{"text":" ","type":"text"},{"text":"of this type may be assigned to a category for every model-generated response, not just","type":"text"},{"text":" ","type":"text"},{"text":"responses that exceed a certain threshold.","type":"text"}],"role":"symbol","fragments":[{"text":"struct","kind":"keyword"},{"kind":"text","text":" "},{"text":"SafetyRating","kind":"identifier"}],"title":"SafetyRating"}}}
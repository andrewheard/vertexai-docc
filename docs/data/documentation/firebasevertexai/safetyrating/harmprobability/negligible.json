{"identifier":{"url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability\/negligible","interfaceLanguage":"swift"},"kind":"symbol","sections":[],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/firebasevertexai\/safetyrating\/harmprobability\/negligible"]}],"schemaVersion":{"minor":3,"major":0,"patch":0},"metadata":{"symbolKind":"case","roleHeading":"Case","title":"SafetyRating.HarmProbability.negligible","externalID":"s:16FirebaseVertexAI12SafetyRatingV15HarmProbabilityO10negligibleyA2EmF","modules":[{"name":"FirebaseVertexAI"}],"fragments":[{"kind":"keyword","text":"case"},{"kind":"text","text":" "},{"text":"negligible","kind":"identifier"}],"role":"symbol","platforms":[{"beta":false,"introducedAt":"15.0","deprecated":false,"name":"iOS","unavailable":false},{"introducedAt":"11.0","beta":false,"name":"macOS","deprecated":false,"unavailable":false},{"beta":false,"deprecated":false,"name":"Mac Catalyst","introducedAt":"15.0","unavailable":false},{"name":"tvOS","beta":false,"introducedAt":"15.0","deprecated":false,"unavailable":false},{"name":"watchOS","introducedAt":"8.0","deprecated":false,"unavailable":false,"beta":false}]},"abstract":[{"text":"The probability is zero or close to zero. For benign content, the probability across all","type":"text"},{"type":"text","text":" "},{"text":"categories will be this value.","type":"text"}],"hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability"]]},"primaryContentSections":[{"declarations":[{"languages":["swift"],"platforms":["macOS"],"tokens":[{"text":"case","kind":"keyword"},{"text":" ","kind":"text"},{"text":"negligible","kind":"identifier"}]}],"kind":"declarations"}],"references":{"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability/negligible":{"kind":"symbol","url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability\/negligible","fragments":[{"text":"case","kind":"keyword"},{"text":" ","kind":"text"},{"text":"negligible","kind":"identifier"}],"type":"topic","role":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability\/negligible","abstract":[{"type":"text","text":"The probability is zero or close to zero. For benign content, the probability across all"},{"text":" ","type":"text"},{"type":"text","text":"categories will be this value."}],"title":"SafetyRating.HarmProbability.negligible"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","kind":"symbol","abstract":[],"title":"FirebaseVertexAI","role":"collection","type":"topic","url":"\/documentation\/firebasevertexai"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating":{"url":"\/documentation\/firebasevertexai\/safetyrating","title":"SafetyRating","role":"symbol","abstract":[{"text":"A type defining potentially harmful media categories and their model-assigned ratings. A value","type":"text"},{"type":"text","text":" "},{"type":"text","text":"of this type may be assigned to a category for every model-generated response, not just"},{"type":"text","text":" "},{"text":"responses that exceed a certain threshold.","type":"text"}],"navigatorTitle":[{"text":"SafetyRating","kind":"identifier"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating","kind":"symbol","type":"topic","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"SafetyRating","kind":"identifier"}]},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability":{"fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"HarmProbability","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability","title":"SafetyRating.HarmProbability","abstract":[{"type":"text","text":"The probability that a given model output falls under a harmful content category. This does"},{"type":"text","text":" "},{"type":"text","text":"not indicate the severity of harm for a piece of content."}],"type":"topic","kind":"symbol","role":"symbol","navigatorTitle":[{"text":"HarmProbability","kind":"identifier"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability"}}}
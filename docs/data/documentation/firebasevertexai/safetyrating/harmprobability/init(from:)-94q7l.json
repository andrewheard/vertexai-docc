{"metadata":{"conformance":{"availabilityPrefix":[{"text":"Available when","type":"text"}],"conformancePrefix":[{"text":"Conforms when","type":"text"}],"constraints":[{"code":"Self","type":"codeVoice"},{"type":"text","text":" conforms to "},{"code":"Decodable","type":"codeVoice"},{"text":" and ","type":"text"},{"code":"RawValue","type":"codeVoice"},{"text":" is ","type":"text"},{"type":"codeVoice","code":"String"},{"type":"text","text":"."}]},"title":"init(from:)","modules":[{"relatedModules":["Swift"],"name":"FirebaseVertexAI"}],"externalID":"s:SYsSeRzSS8RawValueSYRtzrlE4fromxs7Decoder_p_tKcfc::SYNTHESIZED::s:16FirebaseVertexAI12SafetyRatingV15HarmProbabilityO","fragments":[{"text":"init","kind":"identifier"},{"text":"(","kind":"text"},{"text":"from","kind":"externalParam"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"s:s7DecoderP","text":"Decoder"},{"text":") ","kind":"text"},{"text":"throws","kind":"keyword"}],"extendedModule":"Swift","role":"symbol","symbolKind":"init","roleHeading":"Initializer"},"hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability\/RawRepresentable-Implementations"]]},"identifier":{"url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability\/init(from:)-94q7l","interfaceLanguage":"swift"},"schemaVersion":{"minor":3,"patch":0,"major":0},"primaryContentSections":[{"declarations":[{"languages":["swift"],"platforms":["macOS"],"tokens":[{"text":"init","kind":"keyword"},{"kind":"text","text":"("},{"kind":"externalParam","text":"from"},{"text":" ","kind":"text"},{"text":"decoder","kind":"internalParam"},{"text":": ","kind":"text"},{"text":"Decoder","kind":"typeIdentifier","preciseIdentifier":"s:s7DecoderP"},{"kind":"text","text":") "},{"kind":"keyword","text":"throws"}]}],"kind":"declarations"}],"kind":"symbol","variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/firebasevertexai\/safetyrating\/harmprobability\/init(from:)-94q7l"]}],"abstract":[{"type":"text","text":"Inherited from "},{"code":"RawRepresentable.init(from:)","type":"codeVoice"},{"text":".","type":"text"}],"sections":[],"references":{"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability/init(from:)-94q7l":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability\/init(from:)-94q7l","role":"symbol","kind":"symbol","title":"init(from:)","conformance":{"constraints":[{"code":"Self","type":"codeVoice"},{"text":" conforms to ","type":"text"},{"code":"Decodable","type":"codeVoice"},{"type":"text","text":" and "},{"type":"codeVoice","code":"RawValue"},{"type":"text","text":" is "},{"code":"String","type":"codeVoice"},{"type":"text","text":"."}],"availabilityPrefix":[{"type":"text","text":"Available when"}],"conformancePrefix":[{"type":"text","text":"Conforms when"}]},"type":"topic","fragments":[{"text":"init","kind":"identifier"},{"kind":"text","text":"("},{"text":"from","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"Decoder","kind":"typeIdentifier","preciseIdentifier":"s:s7DecoderP"},{"kind":"text","text":") "},{"text":"throws","kind":"keyword"}],"abstract":[],"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability\/init(from:)-94q7l"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating":{"url":"\/documentation\/firebasevertexai\/safetyrating","title":"SafetyRating","role":"symbol","abstract":[{"text":"A type defining potentially harmful media categories and their model-assigned ratings. A value","type":"text"},{"type":"text","text":" "},{"type":"text","text":"of this type may be assigned to a category for every model-generated response, not just"},{"type":"text","text":" "},{"text":"responses that exceed a certain threshold.","type":"text"}],"navigatorTitle":[{"text":"SafetyRating","kind":"identifier"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating","kind":"symbol","type":"topic","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"SafetyRating","kind":"identifier"}]},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability":{"fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"HarmProbability","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability","title":"SafetyRating.HarmProbability","abstract":[{"type":"text","text":"The probability that a given model output falls under a harmful content category. This does"},{"type":"text","text":" "},{"type":"text","text":"not indicate the severity of harm for a piece of content."}],"type":"topic","kind":"symbol","role":"symbol","navigatorTitle":[{"text":"HarmProbability","kind":"identifier"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability/RawRepresentable-Implementations":{"abstract":[],"kind":"article","url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability\/rawrepresentable-implementations","type":"topic","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability\/RawRepresentable-Implementations","role":"collectionGroup","title":"RawRepresentable Implementations"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","kind":"symbol","abstract":[],"title":"FirebaseVertexAI","role":"collection","type":"topic","url":"\/documentation\/firebasevertexai"}}}
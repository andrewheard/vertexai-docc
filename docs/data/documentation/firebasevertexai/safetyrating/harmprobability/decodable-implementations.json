{"identifier":{"url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability\/Decodable-Implementations","interfaceLanguage":"swift"},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/firebasevertexai\/safetyrating\/harmprobability\/decodable-implementations"]}],"sections":[],"kind":"article","metadata":{"title":"Decodable Implementations","modules":[{"name":"FirebaseVertexAI"}],"role":"collectionGroup"},"schemaVersion":{"major":0,"patch":0,"minor":3},"topicSections":[{"title":"Initializers","identifiers":["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability\/init(from:)-3e70m"],"generated":true}],"hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability"]]},"references":{"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability/init(from:)-3e70m":{"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability\/init(from:)-3e70m","title":"init(from:)","fragments":[{"kind":"identifier","text":"init"},{"text":"(","kind":"text"},{"kind":"externalParam","text":"from"},{"text":": ","kind":"text"},{"preciseIdentifier":"s:s7DecoderP","text":"Decoder","kind":"typeIdentifier"},{"text":") ","kind":"text"},{"text":"throws","kind":"keyword"}],"role":"symbol","type":"topic","kind":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability\/init(from:)-3e70m","abstract":[]},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability":{"fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"HarmProbability","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability","title":"SafetyRating.HarmProbability","abstract":[{"type":"text","text":"The probability that a given model output falls under a harmful content category. This does"},{"type":"text","text":" "},{"type":"text","text":"not indicate the severity of harm for a piece of content."}],"type":"topic","kind":"symbol","role":"symbol","navigatorTitle":[{"text":"HarmProbability","kind":"identifier"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","kind":"symbol","abstract":[],"title":"FirebaseVertexAI","role":"collection","type":"topic","url":"\/documentation\/firebasevertexai"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating":{"url":"\/documentation\/firebasevertexai\/safetyrating","title":"SafetyRating","role":"symbol","abstract":[{"text":"A type defining potentially harmful media categories and their model-assigned ratings. A value","type":"text"},{"type":"text","text":" "},{"type":"text","text":"of this type may be assigned to a category for every model-generated response, not just"},{"type":"text","text":" "},{"text":"responses that exceed a certain threshold.","type":"text"}],"navigatorTitle":[{"text":"SafetyRating","kind":"identifier"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating","kind":"symbol","type":"topic","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"SafetyRating","kind":"identifier"}]}}}
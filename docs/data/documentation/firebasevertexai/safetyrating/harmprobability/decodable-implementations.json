{"kind":"article","hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability"]]},"variants":[{"paths":["\/documentation\/firebasevertexai\/safetyrating\/harmprobability\/decodable-implementations"],"traits":[{"interfaceLanguage":"swift"}]}],"sections":[],"schemaVersion":{"patch":0,"minor":3,"major":0},"metadata":{"modules":[{"name":"FirebaseVertexAI"}],"title":"Decodable Implementations","role":"collectionGroup"},"topicSections":[{"title":"Initializers","generated":true,"identifiers":["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability\/init(from:)-3e70m"]}],"identifier":{"url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability\/Decodable-Implementations","interfaceLanguage":"swift"},"references":{"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"abstract":[],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","role":"collection","url":"\/documentation\/firebasevertexai","type":"topic","title":"FirebaseVertexAI","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability/init(from:)-3e70m":{"kind":"symbol","type":"topic","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability\/init(from:)-3e70m","url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability\/init(from:)-3e70m","role":"symbol","abstract":[],"fragments":[{"text":"init","kind":"identifier"},{"kind":"text","text":"("},{"text":"from","kind":"externalParam"},{"kind":"text","text":": "},{"preciseIdentifier":"s:s7DecoderP","kind":"typeIdentifier","text":"Decoder"},{"text":") ","kind":"text"},{"kind":"keyword","text":"throws"}],"title":"init(from:)"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability":{"kind":"symbol","fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"HarmProbability","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability","title":"SafetyRating.HarmProbability","role":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","abstract":[{"type":"text","text":"The probability that a given model output falls under a harmful content category. This does"},{"text":" ","type":"text"},{"text":"not indicate the severity of harm for a piece of content.","type":"text"}],"navigatorTitle":[{"kind":"identifier","text":"HarmProbability"}],"type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating":{"title":"SafetyRating","role":"symbol","type":"topic","url":"\/documentation\/firebasevertexai\/safetyrating","kind":"symbol","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"SafetyRating","kind":"identifier"}],"navigatorTitle":[{"text":"SafetyRating","kind":"identifier"}],"abstract":[{"text":"A type defining potentially harmful media categories and their model-assigned ratings. A value","type":"text"},{"type":"text","text":" "},{"type":"text","text":"of this type may be assigned to a category for every model-generated response, not just"},{"text":" ","type":"text"},{"text":"responses that exceed a certain threshold.","type":"text"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating"}}}
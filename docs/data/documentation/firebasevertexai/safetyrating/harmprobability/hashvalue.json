{"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability\/hashValue"},"primaryContentSections":[{"kind":"declarations","declarations":[{"platforms":["macOS"],"tokens":[{"text":"var","kind":"keyword"},{"text":" ","kind":"text"},{"text":"hashValue","kind":"identifier"},{"text":": ","kind":"text"},{"text":"Int","kind":"typeIdentifier","preciseIdentifier":"s:Si"},{"kind":"text","text":" { "},{"kind":"keyword","text":"get"},{"kind":"text","text":" }"}],"languages":["swift"]}]}],"kind":"symbol","metadata":{"roleHeading":"Instance Property","externalID":"s:SYsSHRzSH8RawValueSYRpzrlE04hashB0Sivp::SYNTHESIZED::s:16FirebaseVertexAI12SafetyRatingV15HarmProbabilityO","role":"symbol","extendedModule":"Swift","conformance":{"constraints":[{"type":"codeVoice","code":"Self"},{"text":" conforms to ","type":"text"},{"type":"codeVoice","code":"Hashable"},{"text":" and ","type":"text"},{"type":"codeVoice","code":"RawValue"},{"type":"text","text":" conforms to "},{"type":"codeVoice","code":"Hashable"},{"type":"text","text":"."}],"conformancePrefix":[{"text":"Conforms when","type":"text"}],"availabilityPrefix":[{"text":"Available when","type":"text"}]},"symbolKind":"property","title":"hashValue","modules":[{"relatedModules":["Swift"],"name":"FirebaseVertexAI"}],"fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"text":"hashValue","kind":"identifier"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Int","preciseIdentifier":"s:Si"}]},"abstract":[{"type":"text","text":"Inherited from "},{"code":"RawRepresentable.hashValue","type":"codeVoice"},{"text":".","type":"text"}],"sections":[],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/firebasevertexai\/safetyrating\/harmprobability\/hashvalue"]}],"schemaVersion":{"major":0,"minor":3,"patch":0},"hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability\/RawRepresentable-Implementations"]]},"references":{"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","kind":"symbol","abstract":[{"type":"text","text":"The probability that a given model output falls under a harmful content category. This does"},{"type":"text","text":" "},{"text":"not indicate the severity of harm for a piece of content.","type":"text"}],"navigatorTitle":[{"text":"HarmProbability","kind":"identifier"}],"fragments":[{"text":"enum","kind":"keyword"},{"kind":"text","text":" "},{"text":"HarmProbability","kind":"identifier"}],"role":"symbol","url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability","type":"topic","title":"SafetyRating.HarmProbability"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability/hashValue":{"role":"symbol","conformance":{"constraints":[{"code":"Self","type":"codeVoice"},{"type":"text","text":" conforms to "},{"type":"codeVoice","code":"Hashable"},{"text":" and ","type":"text"},{"type":"codeVoice","code":"RawValue"},{"type":"text","text":" conforms to "},{"type":"codeVoice","code":"Hashable"},{"type":"text","text":"."}],"conformancePrefix":[{"text":"Conforms when","type":"text"}],"availabilityPrefix":[{"type":"text","text":"Available when"}]},"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability\/hashvalue","kind":"symbol","title":"hashValue","fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"text":"hashValue","kind":"identifier"},{"kind":"text","text":": "},{"text":"Int","kind":"typeIdentifier","preciseIdentifier":"s:Si"}],"type":"topic","abstract":[],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability\/hashValue"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","abstract":[],"url":"\/documentation\/firebasevertexai","role":"collection","type":"topic","title":"FirebaseVertexAI","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating","fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"text":"SafetyRating","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetyrating","navigatorTitle":[{"text":"SafetyRating","kind":"identifier"}],"title":"SafetyRating","type":"topic","abstract":[{"type":"text","text":"A type defining potentially harmful media categories and their model-assigned ratings. A value"},{"type":"text","text":" "},{"text":"of this type may be assigned to a category for every model-generated response, not just","type":"text"},{"type":"text","text":" "},{"type":"text","text":"responses that exceed a certain threshold."}],"kind":"symbol","role":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability/RawRepresentable-Implementations":{"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability\/rawrepresentable-implementations","title":"RawRepresentable Implementations","kind":"article","role":"collectionGroup","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability\/RawRepresentable-Implementations","type":"topic","abstract":[]}}}
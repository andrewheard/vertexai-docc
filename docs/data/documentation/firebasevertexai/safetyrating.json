{"relationshipsSections":[{"kind":"relationships","type":"conformsTo","title":"Conforms To","identifiers":["doc:\/\/FirebaseVertexAI\/Se","doc:\/\/FirebaseVertexAI\/SQ","doc:\/\/FirebaseVertexAI\/SH","doc:\/\/FirebaseVertexAI\/s8SendableP"]}],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/firebasevertexai\/safetyrating"]}],"primaryContentSections":[{"declarations":[{"platforms":["macOS"],"tokens":[{"kind":"keyword","text":"struct"},{"text":" ","kind":"text"},{"text":"SafetyRating","kind":"identifier"}],"languages":["swift"]}],"kind":"declarations"}],"abstract":[{"text":"A type defining potentially harmful media categories and their model-assigned ratings. A value","type":"text"},{"text":" ","type":"text"},{"type":"text","text":"of this type may be assigned to a category for every model-generated response, not just"},{"text":" ","type":"text"},{"text":"responses that exceed a certain threshold.","type":"text"}],"topicSections":[{"title":"Initializers","identifiers":["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/init(category:probability:)"]},{"title":"Instance Properties","identifiers":["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/category","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/probability"]},{"title":"Enumerations","identifiers":["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability"]},{"title":"Default Implementations","identifiers":["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/Decodable-Implementations","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/Equatable-Implementations"],"generated":true}],"kind":"symbol","metadata":{"role":"symbol","platforms":[{"introducedAt":"15.0","deprecated":false,"unavailable":false,"name":"iOS","beta":false},{"deprecated":false,"introducedAt":"11.0","name":"macOS","unavailable":false,"beta":false},{"beta":false,"introducedAt":"15.0","name":"Mac Catalyst","unavailable":false,"deprecated":false},{"deprecated":false,"name":"tvOS","unavailable":false,"introducedAt":"15.0","beta":false},{"unavailable":false,"deprecated":false,"beta":false,"name":"watchOS","introducedAt":"8.0"}],"symbolKind":"struct","navigatorTitle":[{"kind":"identifier","text":"SafetyRating"}],"roleHeading":"Structure","modules":[{"name":"FirebaseVertexAI"}],"externalID":"s:16FirebaseVertexAI12SafetyRatingV","fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"text":"SafetyRating","kind":"identifier"}],"title":"SafetyRating"},"sections":[],"schemaVersion":{"minor":3,"patch":0,"major":0},"hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI"]]},"identifier":{"url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating","interfaceLanguage":"swift"},"references":{"doc://FirebaseVertexAI/SH":{"type":"unresolvable","identifier":"doc:\/\/FirebaseVertexAI\/SH","title":"Swift.Hashable"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/probability":{"role":"symbol","kind":"symbol","abstract":[{"type":"text","text":"The model-generated probability that the content falls under the specified harm "},{"type":"reference","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/category","isActive":true},{"text":".","type":"text"}],"title":"probability","fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"probability"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"s:16FirebaseVertexAI12SafetyRatingV","text":"SafetyRating"},{"text":".","kind":"text"},{"preciseIdentifier":"s:16FirebaseVertexAI12SafetyRatingV15HarmProbabilityO","text":"HarmProbability","kind":"typeIdentifier"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/probability","url":"\/documentation\/firebasevertexai\/safetyrating\/probability","type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/category":{"role":"symbol","kind":"symbol","type":"topic","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/category","title":"category","abstract":[{"type":"text","text":"The category describing the potential harm a piece of content may pose."}],"url":"\/documentation\/firebasevertexai\/safetyrating\/category","fragments":[{"kind":"keyword","text":"let"},{"text":" ","kind":"text"},{"text":"category","kind":"identifier"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"HarmCategory","preciseIdentifier":"s:16FirebaseVertexAI12HarmCategoryO"}]},"doc://FirebaseVertexAI/SQ":{"type":"unresolvable","identifier":"doc:\/\/FirebaseVertexAI\/SQ","title":"Swift.Equatable"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating":{"type":"topic","navigatorTitle":[{"kind":"identifier","text":"SafetyRating"}],"url":"\/documentation\/firebasevertexai\/safetyrating","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating","kind":"symbol","abstract":[{"type":"text","text":"A type defining potentially harmful media categories and their model-assigned ratings. A value"},{"text":" ","type":"text"},{"text":"of this type may be assigned to a category for every model-generated response, not just","type":"text"},{"text":" ","type":"text"},{"text":"responses that exceed a certain threshold.","type":"text"}],"role":"symbol","fragments":[{"text":"struct","kind":"keyword"},{"kind":"text","text":" "},{"text":"SafetyRating","kind":"identifier"}],"title":"SafetyRating"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/init(category:probability:)":{"type":"topic","role":"symbol","kind":"symbol","fragments":[{"text":"init","kind":"identifier"},{"kind":"text","text":"("},{"text":"category","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"HarmCategory","kind":"typeIdentifier","preciseIdentifier":"s:16FirebaseVertexAI12HarmCategoryO"},{"text":", ","kind":"text"},{"text":"probability","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"SafetyRating","kind":"typeIdentifier","preciseIdentifier":"s:16FirebaseVertexAI12SafetyRatingV"},{"text":".","kind":"text"},{"kind":"typeIdentifier","text":"HarmProbability","preciseIdentifier":"s:16FirebaseVertexAI12SafetyRatingV15HarmProbabilityO"},{"kind":"text","text":")"}],"abstract":[{"type":"text","text":"Initializes a new "},{"type":"codeVoice","code":"SafetyRating"},{"text":" instance with the given category and probability.","type":"text"},{"type":"text","text":" "},{"type":"text","text":"Use this initializer for SwiftUI previews or tests."}],"title":"init(category:probability:)","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/init(category:probability:)","url":"\/documentation\/firebasevertexai\/safetyrating\/init(category:probability:)"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"kind":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","type":"topic","url":"\/documentation\/firebasevertexai","abstract":[],"title":"FirebaseVertexAI","role":"collection"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/Decodable-Implementations":{"role":"collectionGroup","kind":"article","url":"\/documentation\/firebasevertexai\/safetyrating\/decodable-implementations","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/Decodable-Implementations","abstract":[],"title":"Decodable Implementations","type":"topic"},"doc://FirebaseVertexAI/s8SendableP":{"type":"unresolvable","identifier":"doc:\/\/FirebaseVertexAI\/s8SendableP","title":"Swift.Sendable"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/Equatable-Implementations":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/Equatable-Implementations","url":"\/documentation\/firebasevertexai\/safetyrating\/equatable-implementations","abstract":[],"role":"collectionGroup","kind":"article","title":"Equatable Implementations","type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability":{"title":"SafetyRating.HarmProbability","navigatorTitle":[{"text":"HarmProbability","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","kind":"symbol","abstract":[{"type":"text","text":"The probability that a given model output falls under a harmful content category. This does"},{"type":"text","text":" "},{"text":"not indicate the severity of harm for a piece of content.","type":"text"}],"role":"symbol","fragments":[{"kind":"keyword","text":"enum"},{"text":" ","kind":"text"},{"text":"HarmProbability","kind":"identifier"}],"type":"topic"},"doc://FirebaseVertexAI/Se":{"type":"unresolvable","identifier":"doc:\/\/FirebaseVertexAI\/Se","title":"Swift.Decodable"}}}
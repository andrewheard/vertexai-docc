{"abstract":[{"type":"text","text":"A type used to specify a threshold for harmful content, beyond which the model will return a"},{"text":" ","type":"text"},{"type":"text","text":"fallback response instead of generated content."}],"topicSections":[{"title":"Initializers","identifiers":["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/init(harmCategory:threshold:)"]},{"title":"Instance Properties","identifiers":["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/harmCategory","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/threshold"]},{"title":"Enumerations","identifiers":["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/BlockThreshold"]}],"primaryContentSections":[{"declarations":[{"languages":["swift"],"tokens":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"text":"SafetySetting","kind":"identifier"}],"platforms":["macOS"]}],"kind":"declarations"}],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting"},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/firebasevertexai\/safetysetting"]}],"kind":"symbol","metadata":{"externalID":"s:16FirebaseVertexAI13SafetySettingV","symbolKind":"struct","title":"SafetySetting","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"SafetySetting","kind":"identifier"}],"navigatorTitle":[{"kind":"identifier","text":"SafetySetting"}],"role":"symbol","roleHeading":"Structure","platforms":[{"unavailable":false,"introducedAt":"15.0","name":"iOS","beta":false,"deprecated":false},{"name":"macOS","beta":false,"deprecated":false,"introducedAt":"11.0","unavailable":false},{"beta":false,"name":"Mac Catalyst","introducedAt":"15.0","deprecated":false,"unavailable":false},{"unavailable":false,"name":"tvOS","deprecated":false,"introducedAt":"15.0","beta":false},{"name":"watchOS","introducedAt":"8.0","unavailable":false,"deprecated":false,"beta":false}],"modules":[{"name":"FirebaseVertexAI"}]},"relationshipsSections":[{"title":"Conforms To","kind":"relationships","type":"conformsTo","identifiers":["doc:\/\/FirebaseVertexAI\/SE"]}],"hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI"]]},"schemaVersion":{"minor":3,"patch":0,"major":0},"sections":[],"references":{"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/harmCategory":{"abstract":[{"type":"text","text":"The category this safety setting should be applied to."}],"type":"topic","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/harmCategory","url":"\/documentation\/firebasevertexai\/safetysetting\/harmcategory","fragments":[{"kind":"keyword","text":"let"},{"text":" ","kind":"text"},{"text":"harmCategory","kind":"identifier"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"HarmCategory","preciseIdentifier":"s:16FirebaseVertexAI12HarmCategoryO"}],"kind":"symbol","title":"harmCategory","role":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/BlockThreshold":{"kind":"symbol","fragments":[{"kind":"keyword","text":"enum"},{"text":" ","kind":"text"},{"text":"BlockThreshold","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetysetting\/blockthreshold","title":"SafetySetting.BlockThreshold","role":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/BlockThreshold","abstract":[{"text":"Block at and beyond a specified ","type":"text"},{"isActive":true,"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","type":"reference"},{"text":".","type":"text"}],"navigatorTitle":[{"kind":"identifier","text":"BlockThreshold"}],"type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/threshold":{"role":"symbol","kind":"symbol","type":"topic","abstract":[{"text":"The threshold describing what content should be blocked.","type":"text"}],"url":"\/documentation\/firebasevertexai\/safetysetting\/threshold","fragments":[{"text":"let","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"threshold"},{"kind":"text","text":": "},{"text":"SafetySetting","preciseIdentifier":"s:16FirebaseVertexAI13SafetySettingV","kind":"typeIdentifier"},{"text":".","kind":"text"},{"text":"BlockThreshold","preciseIdentifier":"s:16FirebaseVertexAI13SafetySettingV14BlockThresholdO","kind":"typeIdentifier"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/threshold","title":"threshold"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"abstract":[],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","role":"collection","url":"\/documentation\/firebasevertexai","type":"topic","title":"FirebaseVertexAI","kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability":{"kind":"symbol","fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"HarmProbability","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability","title":"SafetyRating.HarmProbability","role":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability","abstract":[{"type":"text","text":"The probability that a given model output falls under a harmful content category. This does"},{"text":" ","type":"text"},{"text":"not indicate the severity of harm for a piece of content.","type":"text"}],"navigatorTitle":[{"kind":"identifier","text":"HarmProbability"}],"type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/init(harmCategory:threshold:)":{"abstract":[{"type":"text","text":"Initializes a new safety setting with the given category and threshold."}],"type":"topic","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/init(harmCategory:threshold:)","url":"\/documentation\/firebasevertexai\/safetysetting\/init(harmcategory:threshold:)","fragments":[{"kind":"identifier","text":"init"},{"text":"(","kind":"text"},{"text":"harmCategory","kind":"externalParam"},{"kind":"text","text":": "},{"preciseIdentifier":"s:16FirebaseVertexAI12HarmCategoryO","kind":"typeIdentifier","text":"HarmCategory"},{"kind":"text","text":", "},{"kind":"externalParam","text":"threshold"},{"text":": ","kind":"text"},{"text":"SafetySetting","preciseIdentifier":"s:16FirebaseVertexAI13SafetySettingV","kind":"typeIdentifier"},{"kind":"text","text":"."},{"preciseIdentifier":"s:16FirebaseVertexAI13SafetySettingV14BlockThresholdO","text":"BlockThreshold","kind":"typeIdentifier"},{"text":")","kind":"text"}],"kind":"symbol","title":"init(harmCategory:threshold:)","role":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting":{"kind":"symbol","fragments":[{"kind":"keyword","text":"struct"},{"text":" ","kind":"text"},{"text":"SafetySetting","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetysetting","title":"SafetySetting","role":"symbol","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting","abstract":[{"type":"text","text":"A type used to specify a threshold for harmful content, beyond which the model will return a"},{"text":" ","type":"text"},{"text":"fallback response instead of generated content.","type":"text"}],"navigatorTitle":[{"text":"SafetySetting","kind":"identifier"}],"type":"topic"},"doc://FirebaseVertexAI/SE":{"title":"Swift.Encodable","type":"unresolvable","identifier":"doc:\/\/FirebaseVertexAI\/SE"}}}
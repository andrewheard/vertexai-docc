{"abstract":[{"text":"A type used to specify a threshold for harmful content, beyond which the model will return a","type":"text"},{"type":"text","text":" "},{"type":"text","text":"fallback response instead of generated content."}],"topicSections":[{"title":"Initializers","identifiers":["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/init(harmCategory:threshold:)"]},{"title":"Instance Properties","identifiers":["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/harmCategory","doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/threshold"]},{"title":"Enumerations","identifiers":["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold"]}],"primaryContentSections":[{"kind":"declarations","declarations":[{"languages":["swift"],"tokens":[{"text":"struct","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"SafetySetting"}],"platforms":["macOS"]}]}],"hierarchy":{"paths":[["doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI"]]},"identifier":{"url":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting","interfaceLanguage":"swift"},"metadata":{"platforms":[{"name":"iOS","introducedAt":"15.0","unavailable":false,"beta":false,"deprecated":false},{"name":"macOS","deprecated":false,"introducedAt":"11.0","unavailable":false,"beta":false},{"introducedAt":"15.0","deprecated":false,"unavailable":false,"beta":false,"name":"Mac Catalyst"},{"beta":false,"deprecated":false,"name":"tvOS","unavailable":false,"introducedAt":"15.0"},{"unavailable":false,"beta":false,"introducedAt":"8.0","deprecated":false,"name":"watchOS"}],"navigatorTitle":[{"text":"SafetySetting","kind":"identifier"}],"symbolKind":"struct","title":"SafetySetting","externalID":"s:16FirebaseVertexAI13SafetySettingV","roleHeading":"Structure","modules":[{"name":"FirebaseVertexAI"}],"fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"text":"SafetySetting","kind":"identifier"}],"role":"symbol"},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/firebasevertexai\/safetysetting"]}],"schemaVersion":{"minor":3,"major":0,"patch":0},"relationshipsSections":[{"title":"Conforms To","identifiers":["doc:\/\/FirebaseVertexAI\/SE"],"type":"conformsTo","kind":"relationships"}],"sections":[],"kind":"symbol","references":{"doc://FirebaseVertexAI/documentation/FirebaseVertexAI":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI","kind":"symbol","abstract":[],"title":"FirebaseVertexAI","role":"collection","type":"topic","url":"\/documentation\/firebasevertexai"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting":{"navigatorTitle":[{"kind":"identifier","text":"SafetySetting"}],"url":"\/documentation\/firebasevertexai\/safetysetting","fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"kind":"identifier","text":"SafetySetting"}],"type":"topic","role":"symbol","kind":"symbol","abstract":[{"text":"A type used to specify a threshold for harmful content, beyond which the model will return a","type":"text"},{"type":"text","text":" "},{"type":"text","text":"fallback response instead of generated content."}],"title":"SafetySetting","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/threshold":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/threshold","kind":"symbol","abstract":[{"text":"The threshold describing what content should be blocked.","type":"text"}],"type":"topic","title":"threshold","url":"\/documentation\/firebasevertexai\/safetysetting\/threshold","role":"symbol","fragments":[{"kind":"keyword","text":"let"},{"text":" ","kind":"text"},{"kind":"identifier","text":"threshold"},{"kind":"text","text":": "},{"text":"SafetySetting","kind":"typeIdentifier","preciseIdentifier":"s:16FirebaseVertexAI13SafetySettingV"},{"text":".","kind":"text"},{"text":"HarmBlockThreshold","kind":"typeIdentifier","preciseIdentifier":"s:16FirebaseVertexAI13SafetySettingV18HarmBlockThresholdO"}]},"doc://FirebaseVertexAI/SE":{"type":"unresolvable","identifier":"doc:\/\/FirebaseVertexAI\/SE","title":"Swift.Encodable"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetyRating/HarmProbability":{"fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"HarmProbability","kind":"identifier"}],"url":"\/documentation\/firebasevertexai\/safetyrating\/harmprobability","title":"SafetyRating.HarmProbability","abstract":[{"type":"text","text":"The probability that a given model output falls under a harmful content category. This does"},{"type":"text","text":" "},{"type":"text","text":"not indicate the severity of harm for a piece of content."}],"type":"topic","kind":"symbol","role":"symbol","navigatorTitle":[{"text":"HarmProbability","kind":"identifier"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/HarmBlockThreshold":{"abstract":[{"text":"Block at and beyond a specified ","type":"text"},{"isActive":true,"type":"reference","identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetyRating\/HarmProbability"},{"text":".","type":"text"}],"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/HarmBlockThreshold","url":"\/documentation\/firebasevertexai\/safetysetting\/harmblockthreshold","fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"HarmBlockThreshold","kind":"identifier"}],"kind":"symbol","navigatorTitle":[{"kind":"identifier","text":"HarmBlockThreshold"}],"role":"symbol","title":"SafetySetting.HarmBlockThreshold","type":"topic"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/harmCategory":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/harmCategory","type":"topic","abstract":[{"text":"The category this safety setting should be applied to.","type":"text"}],"title":"harmCategory","url":"\/documentation\/firebasevertexai\/safetysetting\/harmcategory","role":"symbol","fragments":[{"text":"let","kind":"keyword"},{"kind":"text","text":" "},{"text":"harmCategory","kind":"identifier"},{"kind":"text","text":": "},{"text":"HarmCategory","kind":"typeIdentifier","preciseIdentifier":"s:16FirebaseVertexAI12HarmCategoryO"}],"kind":"symbol"},"doc://FirebaseVertexAI/documentation/FirebaseVertexAI/SafetySetting/init(harmCategory:threshold:)":{"identifier":"doc:\/\/FirebaseVertexAI\/documentation\/FirebaseVertexAI\/SafetySetting\/init(harmCategory:threshold:)","title":"init(harmCategory:threshold:)","fragments":[{"text":"init","kind":"identifier"},{"text":"(","kind":"text"},{"kind":"externalParam","text":"harmCategory"},{"kind":"text","text":": "},{"text":"HarmCategory","kind":"typeIdentifier","preciseIdentifier":"s:16FirebaseVertexAI12HarmCategoryO"},{"text":", ","kind":"text"},{"kind":"externalParam","text":"threshold"},{"kind":"text","text":": "},{"text":"SafetySetting","kind":"typeIdentifier","preciseIdentifier":"s:16FirebaseVertexAI13SafetySettingV"},{"text":".","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"s:16FirebaseVertexAI13SafetySettingV18HarmBlockThresholdO","text":"HarmBlockThreshold"},{"text":")","kind":"text"}],"url":"\/documentation\/firebasevertexai\/safetysetting\/init(harmcategory:threshold:)","kind":"symbol","abstract":[{"text":"Initializes a new safety setting with the given category and threshold.","type":"text"}],"role":"symbol","type":"topic"}}}